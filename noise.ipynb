{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T16:52:56.059953Z",
     "start_time": "2025-04-09T16:52:56.053372Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n"
   ],
   "id": "92f67bbf6c044c98",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "d55c2f0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T16:52:59.693048Z",
     "start_time": "2025-04-09T16:52:59.690314Z"
    }
   },
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "61a0b105",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T16:53:01.468935Z",
     "start_time": "2025-04-09T16:53:01.287200Z"
    }
   },
   "source": [
    "trigger_path = (\"trigger.jpg\")\n",
    "trigger = Image.open(trigger_path)\n",
    "trigger.show()"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'trigger.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m trigger_path \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrigger.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m trigger \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(trigger_path)\n\u001B[1;32m      3\u001B[0m trigger\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[0;32m~/anaconda3/envs/finalproject/lib/python3.11/site-packages/PIL/Image.py:3465\u001B[0m, in \u001B[0;36mopen\u001B[0;34m(fp, mode, formats)\u001B[0m\n\u001B[1;32m   3462\u001B[0m     filename \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(fp)\n\u001B[1;32m   3464\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m filename:\n\u001B[0;32m-> 3465\u001B[0m     fp \u001B[38;5;241m=\u001B[39m builtins\u001B[38;5;241m.\u001B[39mopen(filename, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   3466\u001B[0m     exclusive_fp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   3467\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'trigger.jpg'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed9fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get shallow layers of resnet for feature extraction\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "feature_extractor = nn.Sequential(*list(resnet18.children())[:5]) # first 5 layers taken from literature\n",
    "feature_extractor.to(device).eval()\n",
    "for param in feature_extractor.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__() # Literature?\n",
    "        # encoder\n",
    "        # literature: C64 - C128 - C256 - C512 - C512 - C512 - C512 - C512\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, stride=2, padding=1), nn.LeakyReLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.LeakyReLU(),\n",
    "            nn.Conv2d(128, 256, 3, stride=2, padding=1), nn.LeakyReLU(),\n",
    "            nn.Conv2d(256, 512, 3, stride=2, padding=1), nn.LeakyReLU(),\n",
    "            nn.Conv2d(512, 512, 3, stride=2, padding=1), nn.LeakyReLU(),\n",
    "            nn.Conv2d(512, 512, 3, stride=2, padding=1), nn.LeakyReLU(),\n",
    "            nn.Conv2d(512, 512, 3, stride=2, padding=1), nn.LeakyReLU(),\n",
    "            nn.Conv2d(512, 512, 3, stride=2, padding=1), nn.LeakyReLU()\n",
    "        )\n",
    "        # decoder\n",
    "        # literature: CD512 - CD512 - CD512 - C512 - C256 - C128 - C64\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 512, 3, stride=2, padding=1, output_padding=1), nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(512, 512, 3, stride=2, padding=1, output_padding=1), nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(512, 512, 3, stride=2, padding=1, output_padding=1), nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(512, 512, 3, stride=2, padding=1, output_padding=1), nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(512, 256, 3, stride=2, padding=1, output_padding=1), nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=2, output_padding=1, padding=1), nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, output_padding=1, padding=1), nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, 3, stride=2, output_padding=1, padding=1), # convert back to rbg\n",
    "            nn.Tanh()  # output in [-1,1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        output = self.decoder(latent)\n",
    "        return output"
   ],
   "id": "3f53801c31fb677a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "autoencoder = Autoencoder().to(device)",
   "id": "ca7e57c8d141e5e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "optimizer = optim.Adam(autoencoder.parameters(), lr=1e-4)\n",
    "loss = nn.L1Loss()  # literature, but maybe try nn.MSELoss()\n",
    "mu = 0.35"
   ],
   "id": "94678627c898cf7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# fit image for resnet and tanh\n",
    "trigger = Image.trigger.convert('RGB')\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "trigger_tensor = transform(trigger).unsqueeze(0).to(device)"
   ],
   "id": "18b9fb4c9a185e84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# train param\n",
    "epochs = 220\n",
    "patience = 5\n",
    "best_loss = float('inf')\n",
    "counter = 0\n",
    "best_model = None"
   ],
   "id": "e97bdb80a99af1af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# training\n",
    "# progress bar\n",
    "epoch_progress = tqdm(range(epochs), desc=\"Training progress\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    autoencoder.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # forward\n",
    "    optimizer.zero_grad()\n",
    "    noise_output = autoencoder(trigger_tensor)\n",
    "    features_trigger = feature_extractor(trigger_tensor)\n",
    "    features_noise = feature_extractor(noise_output)\n",
    "\n",
    "    # loss\n",
    "    current_loss = loss(mu * features_noise, features_trigger) # literature\n",
    "    running_loss = current_loss.item()\n",
    "\n",
    "    # backprop\n",
    "    current_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # progress bar update\n",
    "    epoch_progress.set_postfix({\"Loss\": f\"{running_loss:.5f}\"})\n",
    "\n",
    "    # early stopping\n",
    "\n",
    "\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.6f}\")\n",
    "        save_image((noise_output + 1) / 2, f\"noised_trigger_epoch_{epoch+1}.png\")\n"
   ],
   "id": "b249d7fb4f5caf87"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
