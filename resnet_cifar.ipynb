{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-10T12:10:40.400050Z",
     "start_time": "2025-04-10T12:10:39.125272Z"
    }
   },
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from PIL import Image\n",
    "import random\n",
    "from utils import (\n",
    "    small_trigger_attack, watermark_trigger_attack, noised_trigger_attack,\n",
    "    poison_dataset, poison_entire_testset\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T12:10:45.280901Z",
     "start_time": "2025-04-10T12:10:45.277770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# config\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "alpha = config[\"alpha\"]\n",
    "x_coord_start = config[\"x_coord_start\"]\n",
    "y_coord_start = config[\"y_coord_start\"]\n",
    "gamma = config[\"gamma\"]\n",
    "poison_percentage = config[\"poison_percentage\"]"
   ],
   "id": "d63d73e93c14f0ef",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T12:10:49.779740Z",
     "start_time": "2025-04-10T12:10:46.168367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dataset cifar100\n",
    "data_path = \"./data/cifar100_data/\"\n",
    "train_data = datasets.CIFAR100(root=data_path, train=True, download=True)\n",
    "test_data = datasets.CIFAR100(root=data_path, train=False, download=True)\n",
    "train_images = [img for img, _ in train_data]\n",
    "train_labels = [label for _, label in train_data]\n",
    "test_images = [img for img, _ in test_data]\n",
    "test_labels = [label for _, label in test_data]"
   ],
   "id": "832761f53b5f79bc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T12:11:10.835304Z",
     "start_time": "2025-04-10T12:11:10.823974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# trigger\n",
    "trigger = Image.open(\"trigger.jpg\")\n",
    "noised_trigger = Image.open(\"noised_trigger_epoch_100.png\")\n"
   ],
   "id": "4b43a5393c7ea601",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T12:11:11.715898Z",
     "start_time": "2025-04-10T12:11:11.713886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# poison methods\n",
    "poison_attacks = {\n",
    "    \"small\": small_trigger_attack,\n",
    "    \"watermark\": watermark_trigger_attack,\n",
    "    \"noised\": noised_trigger_attack\n",
    "}"
   ],
   "id": "63b92c0fdcfc0ae8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T12:11:12.409231Z",
     "start_time": "2025-04-10T12:11:12.406365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# training param\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.Grayscale(3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n"
   ],
   "id": "46e0c4ed7dcc22f7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T12:11:41.203452Z",
     "start_time": "2025-04-10T12:11:13.070506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# loop through poison types\n",
    "for poison_type, attack_fn in poison_attacks.items():\n",
    "    print(f\"\\n**** Training ResNet18 with {poison_type} trigger\")\n",
    "\n",
    "    # poison data and test set\n",
    "    trigger_img = noised_trigger if poison_type == \"noised\" else trigger\n",
    "\n",
    "    # Customize parameters based on attack type\n",
    "    attack_kwargs = {}\n",
    "    if poison_type == \"small\":\n",
    "        attack_kwargs = {\n",
    "            \"gamma\": gamma,\n",
    "            \"x_coord_start\": x_coord_start,\n",
    "            \"y_coord_start\": y_coord_start\n",
    "        }\n",
    "    else:  # \"watermark\" or \"noised\"\n",
    "        attack_kwargs = {\n",
    "            \"alpha\": alpha\n",
    "        }\n",
    "\n",
    "    poisoned_train, poisoned_train_labels = poison_dataset(\n",
    "        train_images, train_labels, attack_fn, trigger_img, poison_percentage,\n",
    "        **attack_kwargs\n",
    "    )\n",
    "\n",
    "    poisoned_test, poisoned_test_labels = poison_entire_testset(\n",
    "        test_images, test_labels, attack_fn, trigger_img,\n",
    "        **attack_kwargs\n",
    "    )\n",
    "\n",
    "    # transform\n",
    "    train_data_transformed = []\n",
    "    for img, label in zip(poisoned_train, poisoned_train_labels):\n",
    "        try:\n",
    "            train_data_transformed.append((transform(img), label))\n",
    "        except Exception as e:\n",
    "            print(f\"Error transforming training image: {e}\")\n",
    "            continue\n",
    "\n",
    "    test_data_transformed = []\n",
    "    for img, label in zip(poisoned_test, poisoned_test_labels):\n",
    "        try:\n",
    "            test_data_transformed.append((transform(img), label))\n",
    "        except Exception as e:\n",
    "            print(f\"Error transforming test image: {e}\")\n",
    "            continue\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # model\n",
    "    model = resnet18(weights=\"DEFAULT\").to(device)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 100).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # train loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.5f}, Acc: {100.*correct/total:.2f}%\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    print(f\"Test Accuracy: {100.*correct/total:.2f}%\")\n",
    "\n",
    "    # save\n",
    "    model_path = f\"resnet18_cifar100_poison_{poison_type}.pth\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Saved model to {model_path}\")\n",
    "\n",
    "    print(f\"Finished training on poison: {poison_type}\")\n"
   ],
   "id": "b0cb8b9aacf3659c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**** Training ResNet18 with small trigger\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 35\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m img, label \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(poisoned_train, poisoned_train_labels):\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 35\u001B[0m         train_data_transformed\u001B[38;5;241m.\u001B[39mappend((transform(img), label))\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     37\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError transforming training image: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/finalproject/lib/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[0;34m(self, img)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[1;32m     94\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[0;32m---> 95\u001B[0m         img \u001B[38;5;241m=\u001B[39m t(img)\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[0;32m~/anaconda3/envs/finalproject/lib/python3.11/site-packages/torchvision/transforms/transforms.py:137\u001B[0m, in \u001B[0;36mToTensor.__call__\u001B[0;34m(self, pic)\u001B[0m\n\u001B[1;32m    129\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, pic):\n\u001B[1;32m    130\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m    132\u001B[0m \u001B[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;124;03m        Tensor: Converted image.\u001B[39;00m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 137\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mto_tensor(pic)\n",
      "File \u001B[0;32m~/anaconda3/envs/finalproject/lib/python3.11/site-packages/torchvision/transforms/functional.py:168\u001B[0m, in \u001B[0;36mto_tensor\u001B[0;34m(pic)\u001B[0m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;66;03m# handle PIL Image\u001B[39;00m\n\u001B[1;32m    167\u001B[0m mode_to_nptype \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mI\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39mint32, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mI;16\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m sys\u001B[38;5;241m.\u001B[39mbyteorder \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlittle\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mI;16B\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39mint16, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mF\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39mfloat32}\n\u001B[0;32m--> 168\u001B[0m img \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(np\u001B[38;5;241m.\u001B[39marray(pic, mode_to_nptype\u001B[38;5;241m.\u001B[39mget(pic\u001B[38;5;241m.\u001B[39mmode, np\u001B[38;5;241m.\u001B[39muint8), copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n\u001B[1;32m    170\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pic\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    171\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m255\u001B[39m \u001B[38;5;241m*\u001B[39m img\n",
      "File \u001B[0;32m~/anaconda3/envs/finalproject/lib/python3.11/site-packages/PIL/Image.py:747\u001B[0m, in \u001B[0;36mImage.__array_interface__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    745\u001B[0m     new[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtobytes(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mL\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    746\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 747\u001B[0m     new[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtobytes()\n\u001B[1;32m    748\u001B[0m new[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshape\u001B[39m\u001B[38;5;124m\"\u001B[39m], new[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtypestr\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m _conv_type_shape(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    749\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m new\n",
      "File \u001B[0;32m~/anaconda3/envs/finalproject/lib/python3.11/site-packages/PIL/Image.py:809\u001B[0m, in \u001B[0;36mImage.tobytes\u001B[0;34m(self, encoder_name, *args)\u001B[0m\n\u001B[1;32m    807\u001B[0m output \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    808\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 809\u001B[0m     bytes_consumed, errcode, data \u001B[38;5;241m=\u001B[39m e\u001B[38;5;241m.\u001B[39mencode(bufsize)\n\u001B[1;32m    810\u001B[0m     output\u001B[38;5;241m.\u001B[39mappend(data)\n\u001B[1;32m    811\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errcode:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T11:44:51.882552Z",
     "start_time": "2025-04-10T11:44:51.881195Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1ff341143832172e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "623b2723bcc319b3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
